{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e658ebc",
   "metadata": {},
   "source": [
    "# Informe de solución\n",
    "---\n",
    "### Descripción del objetivo\n",
    "\n",
    "Al operador de telecomunicaciones Interconnect le gustaría poder pronosticar su tasa de cancelación de clientes con la finalidad de poder crear una estrategia de retención mediante descuentos y promociones.\n",
    "\n",
    "Sus principales servicios son:\n",
    "- Telefonía fija.\n",
    "- Internet por línea telefónica o fibra óptica.\n",
    "\n",
    "**Objetivo principal**: Crear un modelo predictivo de **clasificación** que arroje que clientes podrían cancelar sus servicios.  \n",
    "(El cliente 'x' va a cancelar?, sí (1) o no (0)?)\n",
    "\n",
    "## Pasos que se realizaron\n",
    "\n",
    "1- Realizamos el preprocesamiento y análisis exploratotio de datos.   \n",
    "\n",
    "    Parte 1:\n",
    "* 1.1.1 Examinación y estudio de datos.  \n",
    "* 1.1.2 Unificación de los datasets (4) mediante columna en común ('customerID').  \n",
    "* 1.1.3 Limpiamos y formateamos el dataset unificado mediante una función (minúsculas y reemplazo de guiones).  \n",
    "* 1.1.4 Enriquecimos datasets con nuevas columnas ('loyalty_months').     \n",
    "* 1.1.5 Eiminamos columnas irrelevantes.\n",
    "* 1.1.6 Reordenamos, columnas y tratamos filas duplicadas y valores ausentes.\n",
    "* 1.1.7 Cambiamos tipo de datos (object-datetime, object-int).  \n",
    "\n",
    "Parte 2:\n",
    "* 1.2.1 Estudiamos estadísticas descriptivas de todas las columnas.\n",
    "* 1.2.2 Graficamos la distribución de las características numéricas y presentamos con porcentajes la distribución de las características categóricas y binarias.\n",
    "* 1.2.3 Investigamos si existían 'outliers' en las características.\n",
    "* 1.2.4 Identificamos correlaciones y patrones de la variable objetivo con las características.\n",
    "* 1.2.5 Descrubimos la existencia de un desbalance de clases en la variable objetivo.\n",
    "* 1.2.6 Contestamos hipótesis (el primero con cálculos matemáticos y el segundo con prueba estadística).\n",
    "\n",
    "\n",
    "2- Preparación y entrenamiento del modelo (clasificación).\n",
    "\n",
    "* 2.1 Creamos función 'upsample' para el desbalance de clases.\n",
    "* 2.2 Dividimos el dataset 2 veces, el primero sin modificar y el segundo con 'One-hot encoding'. Ambas divisiones fueron distribuidas de la siguiente manera: entrenamiento (60%), validación (20%) y prueba (20%).\n",
    "* 2.3 Entrenamos modelo dummy como prueba de cordura.\n",
    "* 2.4 Entrenamos modelos de regresión logística, árbol de decisión, bosque aleatorio y light gbm.\n",
    "\n",
    "\n",
    "3- Prueba de los modelos y elección del mejor\n",
    "* 3.1 Probamos los mejores modelos (regresión logística y light gbm).\n",
    "* 3.2 Mostramos resultados de métricas de ambos modelos.\n",
    "* 3.3 Elegimos el más eficiente y concluimos eleccón.\n",
    "\n",
    "\n",
    "4- Conclusiones del proyecto.\n",
    "* 4.1 Consluimos con la explicación de las métricas del modelo y con el objetivo del proyecto alcanzado.\n",
    "\n",
    "**Nota**: Todos los pasos fueron del plan de trabajo fueron realizados, en todo caso se agregaron los siguientes puntos: 1.2.3, 1.2.5, 2.2 y 2.3.\n",
    "\n",
    "## Dificultades enfrentadas en el proyecto\n",
    "\n",
    "\n",
    "---\n",
    "**1.1.6** Por la unificación de los datasets se crearon de manera artificial valores ausentes, tuvimos que investigar de donde provenían y decidir como tratarlos, NO se eliminaron ya que correspondían al 21% de todo el dataset. La decisión final fue reeempoplazar los valores ausentes 'Nan' con 'no'. Anexo evidencia:\n",
    "\n",
    "'Datos totales': 7032  \n",
    "internet_service     1520  \n",
    "online_security      1520  \n",
    "online_backup        1520  \n",
    "device_protection    1520  \n",
    "tech_support         1520  \n",
    "streaming_tv         1520  \n",
    "streaming_movies     1520  \n",
    "multiple_lines        680  \n",
    "dtype: int64  \n",
    "\n",
    "---\n",
    "\n",
    "**1.1.7** Modificamos la columna obejtivo 'end_date':\n",
    "* a) Primero creamos una nueva columna con los meses de lealtad de los clientes 'loyalty_months'.\n",
    "* b) Después creamos la nueva colulmna objetivo **'cancelation'** de forma binaria 0 para 'no' y 1 para 'si'.\n",
    "* c) Finalmente reacomodamos columnas para mejor visualización y análisis.\n",
    "Anexo evidencias:\n",
    "\n",
    "-Antes de los cambios:\n",
    "\n",
    "customerID: 7590-VHVEG  \n",
    "BeginDate:\t2020-01-01  \n",
    "EndDate:    No  \n",
    "Type:       Month-to-month    \n",
    "\n",
    "-Después de realizar los cambios:\n",
    "\n",
    "customer_id: 7590_vhveg  \n",
    "begin_date: 2020-01-01  \n",
    "cancelation: 0  \n",
    "loyalty_months: 1  \n",
    "monthly_charges: 29.85  \n",
    "total_charges: 29.85  \n",
    "payment_method: electronic_check\n",
    "type: monthly\n",
    "\n",
    "---\n",
    "\n",
    "**2.2** Me dí cuenta que era necesario tratar los datos para algunos modelos y para otros no. Por ejemplo todos trabajan con 'one-hot encoding' pero light gbm trabaja con categorías nativas, por lo cual se dividio en conjuntos diferentes. Anexo evidencia:\n",
    "\n",
    "* Conjuntos sin 'one-hot encoding':\n",
    "\n",
    "features_train_lgbm = df_train_lgbm.drop(['cancelation'], axis=1)  \n",
    "target_train_lgbm = df_train_lgbm['cancelation']  \n",
    "features_valid_lgbm = df_valid_lgbm.drop(['cancelation'], axis=1)  \n",
    "target_valid_lgbm = df_valid_lgbm['cancelation']  \n",
    "features_test_lgbm = df_test_lgbm.drop(['cancelation'], axis=1)  \n",
    "target_test_lgbm = df_test_lgbm['cancelation']  \n",
    "\n",
    "* Conjuntos con 'one-hot encoding':\n",
    "\n",
    "df_ohe = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "features_train = df_train.drop(['cancelation'], axis=1)  \n",
    "target_train = df_train['cancelation']  \n",
    "features_valid = df_valid.drop(['cancelation'], axis=1)  \n",
    "target_valid = df_valid['cancelation']  \n",
    "features_test = df_test.drop(['cancelation'], axis=1)  \n",
    "target_test = df_test['cancelation']  \n",
    "\n",
    "---\n",
    "\n",
    "**2.4** Necesite escalar las columnas numéricas para el modelo de regresión logística mediante la creación de una copia 'features' a 'features_sc' para poder aplicar 'StandardScaler()' mejorando las métricas. Anexo evidencia:\n",
    "  \n",
    "features_train_sc = features_train.copy()  \n",
    "features_valid_sc = features_valid.copy()  \n",
    "features_test_sc = features_test.copy()  \n",
    "\n",
    "numeric = ['loyalty_months', 'monthly_charges', 'total_charges']  \n",
    "\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(features_train[numeric])  \n",
    "features_train_sc[numeric] = scaler.transform(features_train_sc[numeric])  \n",
    "features_valid_sc[numeric] = scaler.transform(features_valid_sc[numeric])  \n",
    "features_test_sc[numeric] = scaler.transform(features_test_sc[numeric])  \n",
    "\n",
    "\n",
    "## Pasos clave para resolver el proyecto\n",
    " \n",
    "1- Unificar datasets.  \n",
    "2- Crear columna target 'cancelation' y característica 'loyalty_months'.  \n",
    "3- Invrstigación de desbalance de clases.  \n",
    "4- Creación de función 'upsample' para aplicar el método de sobremuestreo.  \n",
    "5- Dividir el dataset en dos bloques, el primero para light gbm y el segundo para el resto con 'one-hot'.  \n",
    "6- Creación de bucles 'for' dentro de los modelos para encontrar los mejores parámetros (repeat, est, etc).  \n",
    "7- Utilizar la métrica 'Accuracy' aparte de la métrica 'AUC-ROC' para poder elegir el mejor modelo.  \n",
    "\n",
    "\n",
    "## Modelo elegido\n",
    "\n",
    "Elegimos el modelo de **Light GBM** por su puntuación en 'Accuracy' y 'F1' más alto que la regresión lineal, aunque la la métrica 'AUC-ROC' es levemente inferior por solo poco más de 1 punto pocentual.  \n",
    "\n",
    "**- Métricas obtenidas:**  \n",
    "\n",
    "**AUC-ROC**: 0.8321  \n",
    "**Accuracy**: 0.7413  \n",
    "**F1-score**: 0.6136  \n",
    "\n",
    "**- Explicación de métricas**\n",
    "- F1 score: El modelo tiene un balance entre precisión y recall con el **61.5%** de efectividad balanceada.  \n",
    "- Accuracy: Con una puntuación de **74%** el modelo nos dice que acierta en la respuesta correcta 74 veces de cada 100.\n",
    "- Auc-roc: Se logro una puntuación de **83%**, lo que significa que el modelo tiene 83.0% de probabilidad de distinguir correctamente entre clases.  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
